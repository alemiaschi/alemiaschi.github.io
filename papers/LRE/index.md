---
title: "Parallel Trees: a novel resource with aligned dependency and constituency syntactic representations"
date: 2025-06-10T00:00:00Z
venue: Language Resources and Evaluation (LRE)
author: ["Chiara Alzetta", "Alessio Miaschi", "Felice Dell'Orletta", "Giulia Venturi", "Simonetta Montemagni"]
summary: "The paper introduces Parallel Trees, a novel multilingual treebank collection that includes 20 treebanks for 10 languages. The distinguishing property of this resource is that the sentences of each language are annotated using two syntactic representation paradigms (SRPs), respectively based on the notions of dependency and constituency. By aligning the annotations of existing resources, Parallel Trees represents an example of exploiting pre-existing treebanks to adapt them to novel applications. To illustrate its potential, we present a case study where the resource is employed as a benchmark to investigate whether and how BERT, one of the first prominent neural language models (NLMs), is sensitive to the dependency- and constituency-based approaches for representing the syntactic structure of a sentence. The case study results indicate that the model’s sensitivity fluctuates across languages and experimental settings. The unique nature of the Parallel Trees resource creates the prerequisites for innovative studies comparing dependency and phrase-structure trees, allowing for more focused investigations without the interference of lexical variation."

editPost:
    URL: "https://link.springer.com/journal/10579"
    Text: "Language Resources and Evaluation (LRE)"

---

##### Download

+ [Paper](https://link.springer.com/article/10.1007/s10579-025-09826-3)

---

##### Abstract

The paper introduces Parallel Trees, a novel multilingual treebank collection that includes 20 treebanks for 10 languages. The distinguishing property of this resource is that the sentences of each language are annotated using two syntactic representation paradigms (SRPs), respectively based on the notions of dependency and constituency. By aligning the annotations of existing resources, Parallel Trees represents an example of exploiting pre-existing treebanks to adapt them to novel applications. To illustrate its potential, we present a case study where the resource is employed as a benchmark to investigate whether and how BERT, one of the first prominent neural language models (NLMs), is sensitive to the dependency- and constituency-based approaches for representing the syntactic structure of a sentence. The case study results indicate that the model’s sensitivity fluctuates across languages and experimental settings. The unique nature of the Parallel Trees resource creates the prerequisites for innovative studies comparing dependency and phrase-structure trees, allowing for more focused investigations without the interference of lexical variation.

---
##### Citation

```BibTeX
@article{alzetta2025parallel,
  title={Parallel Trees: a novel resource with aligned dependency and constituency syntactic representations},
  author={Alzetta, Chiara and Miaschi, Alessio and Dell’Orletta, Felice and Venturi, Giulia and Montemagni, Simonetta},
  journal={Language Resources and Evaluation},
  pages={1--41},
  year={2025},
  publisher={Springer}
}
