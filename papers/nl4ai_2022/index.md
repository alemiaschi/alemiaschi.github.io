---
title: "Evaluating Text-To-Text Framework for Topic and Style Classification of Italian texts"
date: 2022-11-10T00:00:00Z
venue: NL4AI @ AIxIA 2022
author: ["Michele Papucci", "Chiara De Nigris", "Alessio Miaschi", "Felice Dell'Orletta"]
summary: "In this paper, we propose an extensive evaluation of the first text-to-text Italian Neural Language Model (NLM), IT5, on a classification scenario. In particular, we test the performance of IT5 on several tasks involving both the classification of the topic and the style of a set of Italian posts. We assess the model in two different configurations, single- and multi-task classification, and we compare it with a more traditional NLM based on the Transformer architecture (i.e. BERT). Moreover, we test its performance in a few-shot learning scenario. We also perform a qualitative investigation on the impact of label representations in modeling the classification of the IT5 model. Results show that IT5 could achieve good results, although generally lower than the BERT model. Nevertheless, we observe a significant performance improvement of the Text-to-text model in a multi-task classification scenario. Finally, we found that altering the representation of the labels mainly impacts the classification of the topic"

editPost:
    URL: "http://sag.art.uniroma2.it/NL4AI/call-for-papers-3/"
    Text: "Proceedings of the Workshop on Natural Language for Artificial Intelligence (NL4AI @ AIxIA 2022)"

---

##### Download

+ [Paper](https://ceur-ws.org/Vol-3287/paper8.pdf)

---

##### Abstract

In this paper, we propose an extensive evaluation of the first text-to-text Italian Neural Language Model (NLM), IT5, on a classification scenario. In particular, we test the performance of IT5 on several tasks involving both the classification of the topic and the style of a set of Italian posts. We assess the model in two different configurations, single- and multi-task classification, and we compare it with a more traditional NLM based on the Transformer architecture (i.e. BERT). Moreover, we test its performance in a few-shot learning scenario. We also perform a qualitative investigation on the impact of label representations in modeling the classification of the IT5 model. Results show that IT5 could achieve good results, although generally lower than the BERT model. Nevertheless, we observe a significant performance improvement of the Text-to-text model in a multi-task classification scenario. Finally, we found that altering the representation of the labels mainly impacts the classification of the topic

---

##### Citation

```BibTeX
@inproceedings{papucci2022evaluating_text_to_text,
  title={Evaluating Text-To-Text Framework for Topic and Style Classification of Italian texts},
  author={Papucci, Michele and De Nigris, Chiara and Miaschi, Alessio and Dell'Orletta, Felice},
  booktitle={Proceedings of 6th Workshop on Natural Language for Artificial Intelligence (NL4AI 2022)},
  year={2022}
}


