<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors | Alessio Miaschi</title>
<meta name="keywords" content="">
<meta name="description" content="Recent advancements in Generative AI and Large Language Models (LLMs) have enabled the creation of highly realistic synthetic content, raising concerns about the potential for malicious use, such as misinformation and manipulation. Moreover, detecting Machine-Generated Text (MGT) remains challenging due to the lack of robust benchmarks that assess generalization to real-world scenarios. In this work, we evaluate the resilience of state-of-the-art MGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed adversarial attacks. We develop a pipeline that fine-tunes language models using Direct Preference Optimization (DPO) to shift the MGT style toward human-written text (HWT), obtaining generations more challenging to detect by current models. Additionally, we analyze the linguistic shifts induced by the alignment and how detectors rely on “linguistic shortcuts” to detect texts. Our results show that detectors can be easily fooled with relatively few examples, resulting in a significant drop in detecting performances. This highlights the importance of improving detection methods and making them robust to unseen in-domain texts. We release code, models, and data to support future research on more robust MGT detection benchmarks.">
<meta name="author" content="Andrea Pedrotti,&thinsp;Michele Papucci,&thinsp;Cristiano Ciaccio,&thinsp;Alessio Miaschi,&thinsp;Giovanni Puccetti,&thinsp;Felice Dell&#39;Orletta,&thinsp;Andrea Esuli">
<link rel="canonical" href="http://localhost:1313/papers/acl_2025_1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.ac30954b7ea20660ca1cb473400ecede9e601f17674446536180d3ca00f03328.css" integrity="sha256-rDCVS36iBmDKHLRzQA7O3p5gHxdnREZTYYDTygDwMyg=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/papers/acl_2025_1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:url" content="http://localhost:1313/papers/acl_2025_1/">
  <meta property="og:site_name" content="Alessio Miaschi">
  <meta property="og:title" content="Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors">
  <meta property="og:description" content="Recent advancements in Generative AI and Large Language Models (LLMs) have enabled the creation of highly realistic synthetic content, raising concerns about the potential for malicious use, such as misinformation and manipulation. Moreover, detecting Machine-Generated Text (MGT) remains challenging due to the lack of robust benchmarks that assess generalization to real-world scenarios. In this work, we evaluate the resilience of state-of-the-art MGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed adversarial attacks. We develop a pipeline that fine-tunes language models using Direct Preference Optimization (DPO) to shift the MGT style toward human-written text (HWT), obtaining generations more challenging to detect by current models. Additionally, we analyze the linguistic shifts induced by the alignment and how detectors rely on “linguistic shortcuts” to detect texts. Our results show that detectors can be easily fooled with relatively few examples, resulting in a significant drop in detecting performances. This highlights the importance of improving detection methods and making them robust to unseen in-domain texts. We release code, models, and data to support future research on more robust MGT detection benchmarks.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="papers">
    <meta property="article:published_time" content="2025-07-27T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-07-27T00:00:00+00:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors">
<meta name="twitter:description" content="Recent advancements in Generative AI and Large Language Models (LLMs) have enabled the creation of highly realistic synthetic content, raising concerns about the potential for malicious use, such as misinformation and manipulation. Moreover, detecting Machine-Generated Text (MGT) remains challenging due to the lack of robust benchmarks that assess generalization to real-world scenarios. In this work, we evaluate the resilience of state-of-the-art MGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed adversarial attacks. We develop a pipeline that fine-tunes language models using Direct Preference Optimization (DPO) to shift the MGT style toward human-written text (HWT), obtaining generations more challenging to detect by current models. Additionally, we analyze the linguistic shifts induced by the alignment and how detectors rely on “linguistic shortcuts” to detect texts. Our results show that detectors can be easily fooled with relatively few examples, resulting in a significant drop in detecting performances. This highlights the importance of improving detection methods and making them robust to unseen in-domain texts. We release code, models, and data to support future research on more robust MGT detection benchmarks.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Publications",
      "item": "http://localhost:1313/papers/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors",
      "item": "http://localhost:1313/papers/acl_2025_1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors",
  "name": "Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors",
  "description": "Recent advancements in Generative AI and Large Language Models (LLMs) have enabled the creation of highly realistic synthetic content, raising concerns about the potential for malicious use, such as misinformation and manipulation. Moreover, detecting Machine-Generated Text (MGT) remains challenging due to the lack of robust benchmarks that assess generalization to real-world scenarios. In this work, we evaluate the resilience of state-of-the-art MGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed adversarial attacks. We develop a pipeline that fine-tunes language models using Direct Preference Optimization (DPO) to shift the MGT style toward human-written text (HWT), obtaining generations more challenging to detect by current models. Additionally, we analyze the linguistic shifts induced by the alignment and how detectors rely on “linguistic shortcuts” to detect texts. Our results show that detectors can be easily fooled with relatively few examples, resulting in a significant drop in detecting performances. This highlights the importance of improving detection methods and making them robust to unseen in-domain texts. We release code, models, and data to support future research on more robust MGT detection benchmarks.",
  "keywords": [
    
  ],
  "articleBody": "Download Paper Abstract Recent advancements in Generative AI and Large Language Models (LLMs) have enabled the creation of highly realistic synthetic content, raising concerns about the potential for malicious use, such as misinformation and manipulation. Moreover, detecting Machine-Generated Text (MGT) remains challenging due to the lack of robust benchmarks that assess generalization to real-world scenarios. In this work, we evaluate the resilience of state-of-the-art MGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed adversarial attacks. We develop a pipeline that fine-tunes language models using Direct Preference Optimization (DPO) to shift the MGT style toward human-written text (HWT), obtaining generations more challenging to detect by current models. Additionally, we analyze the linguistic shifts induced by the alignment and how detectors rely on “linguistic shortcuts” to detect texts. Our results show that detectors can be easily fooled with relatively few examples, resulting in a significant drop in detecting performances. This highlights the importance of improving detection methods and making them robust to unseen in-domain texts. We release code, models, and data to support future research on more robust MGT detection benchmarks.\nCitation @inproceedings{pedrotti-etal-2025-stress, title = \"Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors\", author = \"Pedrotti, Andrea and Papucci, Michele and Ciaccio, Cristiano and Miaschi, Alessio and Puccetti, Giovanni and Dell{'}Orletta, Felice and Esuli, Andrea\", editor = \"Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher\", booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\", month = jul, year = \"2025\", address = \"Vienna, Austria\", publisher = \"Association for Computational Linguistics\", url = \"https://aclanthology.org/2025.findings-acl.156/\", doi = \"10.18653/v1/2025.findings-acl.156\", pages = \"3010--3031\", ISBN = \"979-8-89176-256-5\", abstract = \"Recent advancements in Generative AI and Large Language Models (LLMs) have enabled the creation of highly realistic synthetic content, raising concerns about the potential for malicious use, such as misinformation and manipulation. Moreover, detecting Machine-Generated Text (MGT) remains challenging due to the lack of robust benchmarks that assess generalization to real-world scenarios. In this work, we evaluate the resilience of state-of-the-art MGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed adversarial attacks. We develop a pipeline that fine-tunes language models using Direct Preference Optimization (DPO) to shift the MGT style toward human-written text (HWT), obtaining generations more challenging to detect by current models. Additionally, we analyze the linguistic shifts induced by the alignment and how detectors rely on ``linguistic shortcuts'' to detect texts. Our results show that detectors can be easily fooled with relatively few examples, resulting in a significant drop in detecting performances. This highlights the importance of improving detection methods and making them robust to unseen in-domain texts. We release code, models, and data to support future research on more robust MGT detection benchmarks.\" } ",
  "wordCount" : "450",
  "inLanguage": "en",
  "datePublished": "2025-07-27T00:00:00Z",
  "dateModified": "2025-07-27T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Andrea Pedrotti"
  }, {
    "@type": "Person",
    "name": "Michele Papucci"
  }, {
    "@type": "Person",
    "name": "Cristiano Ciaccio"
  }, {
    "@type": "Person",
    "name": "Alessio Miaschi"
  }, {
    "@type": "Person",
    "name": "Giovanni Puccetti"
  }, {
    "@type": "Person",
    "name": "Felice Dell'Orletta"
  }, {
    "@type": "Person",
    "name": "Andrea Esuli"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/papers/acl_2025_1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Alessio Miaschi",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Alessio Miaschi">
                <img src="http://localhost:1313/logo.jpg" alt="" aria-label="logo"
                    height="18"
                    width="18">Alessio Miaschi</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/news/" title="News">
                    <span>News</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/papers/" title="Papers">
                    <span>Papers</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/courses/" title="Courses &amp; Theses">
                    <span>Courses &amp; Theses</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/talks/" title="Talks">
                    <span>Talks</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/projects/" title="Resources &amp; Projects">
                    <span>Resources &amp; Projects</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors
    </h1>
    <div class="post-meta"><span title='2025-07-27 00:00:00 +0000 UTC'>July 2025</span>&nbsp;&middot;&nbsp;Andrea Pedrotti,&thinsp;Michele Papucci,&thinsp;Cristiano Ciaccio,&thinsp;Alessio Miaschi,&thinsp;Giovanni Puccetti,&thinsp;Felice Dell'Orletta,&thinsp;Andrea Esuli&nbsp;&middot;&nbsp;<a href="https://2025.aclweb.org/" rel="noopener noreferrer" target="_blank">Proceedings of the Findings of the 2025 Annual Meeting of the Association for Computational Linguistics (Findings of ACL 2025, Vienna, Austria)</a>

</div>
  </header> 
  <div class="post-content"><h5 id="download">Download</h5>
<ul>
<li><a href="https://aclanthology.org/2025.findings-acl.156.pdf" target="_blank">Paper</a></li>
</ul>
<hr>
<h5 id="abstract">Abstract</h5>
<p>Recent advancements in Generative AI and Large Language Models (LLMs) have enabled the creation of highly realistic synthetic content, raising concerns about the potential for malicious use, such as misinformation and manipulation. Moreover, detecting Machine-Generated Text (MGT) remains challenging due to the lack of robust benchmarks that assess generalization to real-world scenarios. In this work, we evaluate the resilience of state-of-the-art MGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed adversarial attacks. We develop a pipeline that fine-tunes language models using Direct Preference Optimization (DPO) to shift the MGT style toward human-written text (HWT), obtaining generations more challenging to detect by current models. Additionally, we analyze the linguistic shifts induced by the alignment and how detectors rely on “linguistic shortcuts” to detect texts. Our results show that detectors can be easily fooled with relatively few examples, resulting in a significant drop in detecting performances. This highlights the importance of improving detection methods and making them robust to unseen in-domain texts. We release code, models, and data to support future research on more robust MGT detection benchmarks.</p>
<hr>
<h5 id="citation">Citation</h5>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-BibTeX" data-lang="BibTeX"><span style="display:flex;"><span><span style="color:#0a0;text-decoration:underline">@inproceedings</span>{pedrotti-etal-2025-stress,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">title</span> = <span style="color:#a50">&#34;Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">author</span> = <span style="color:#a50">&#34;Pedrotti, Andrea  and
</span></span></span><span style="display:flex;"><span><span style="color:#a50">      Papucci, Michele  and
</span></span></span><span style="display:flex;"><span><span style="color:#a50">      Ciaccio, Cristiano  and
</span></span></span><span style="display:flex;"><span><span style="color:#a50">      Miaschi, Alessio  and
</span></span></span><span style="display:flex;"><span><span style="color:#a50">      Puccetti, Giovanni  and
</span></span></span><span style="display:flex;"><span><span style="color:#a50">      Dell{&#39;}Orletta, Felice  and
</span></span></span><span style="display:flex;"><span><span style="color:#a50">      Esuli, Andrea&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">editor</span> = <span style="color:#a50">&#34;Che, Wanxiang  and
</span></span></span><span style="display:flex;"><span><span style="color:#a50">      Nabende, Joyce  and
</span></span></span><span style="display:flex;"><span><span style="color:#a50">      Shutova, Ekaterina  and
</span></span></span><span style="display:flex;"><span><span style="color:#a50">      Pilehvar, Mohammad Taher&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">booktitle</span> = <span style="color:#a50">&#34;Findings of the Association for Computational Linguistics: ACL 2025&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">month</span> = <span style="color:#a00">jul</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">year</span> = <span style="color:#a50">&#34;2025&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">address</span> = <span style="color:#a50">&#34;Vienna, Austria&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">publisher</span> = <span style="color:#a50">&#34;Association for Computational Linguistics&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">url</span> = <span style="color:#a50">&#34;https://aclanthology.org/2025.findings-acl.156/&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">doi</span> = <span style="color:#a50">&#34;10.18653/v1/2025.findings-acl.156&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">pages</span> = <span style="color:#a50">&#34;3010--3031&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">ISBN</span> = <span style="color:#a50">&#34;979-8-89176-256-5&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#1e90ff">abstract</span> = <span style="color:#a50">&#34;Recent advancements in Generative AI and Large Language Models (LLMs) have enabled the creation of highly realistic synthetic content, raising concerns about the potential for malicious use, such as misinformation and manipulation. Moreover, detecting Machine-Generated Text (MGT) remains challenging due to the lack of robust benchmarks that assess generalization to real-world scenarios. In this work, we evaluate the resilience of state-of-the-art MGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed adversarial attacks. We develop a pipeline that fine-tunes language models using Direct Preference Optimization (DPO) to shift the MGT style toward human-written text (HWT), obtaining generations more challenging to detect by current models. Additionally, we analyze the linguistic shifts induced by the alignment and how detectors rely on ``linguistic shortcuts&#39;&#39; to detect texts. Our results show that detectors can be easily fooled with relatively few examples, resulting in a significant drop in detecting performances. This highlights the importance of improving detection methods and making them robust to unseen in-domain texts. We release code, models, and data to support future research on more robust MGT detection benchmarks.&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><hr>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 Alessio Miaschi</span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">hugo</a>, <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">papermod</a>, &amp;
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">hugo-website</a>.
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
