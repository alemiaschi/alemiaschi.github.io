---
title: "Is Neural Language Model Perplexity Related to Readability?"
date: 2020-12-10T00:00:00Z
venue: CLiC-it 2020
author: ["Alessio Miaschi", "Chiara Alzetta", "Dominique Brunato", "Felice Dell'Orletta", "Giulia Venturi"]
summary: "This paper explores the relationship between Neural Language Model (NLM) perplexity and sentence readability. Starting from the evidence that NLMs implicitly acquire sophisticated linguistic knowledge from a huge amount of training data, our goal is to investigate whether perplexity is affected by linguistic features used to automatically assess sentence readability and if there is a correlation between the two metrics. Our findings suggest that this correlation is actually quite weak and the two metrics are affected by different linguistic phenomena."

editPost:
    URL: "https://clic2020.ilc.cnr.it/"
    Text: "Proceedings of the Seventh Italian Conference on Computational Linguistics (CLiC-it 2020)"

---

##### Download

+ [Paper](https://ceur-ws.org/Vol-2769/paper_57.pdf)

---

##### Abstract

This paper explores the relationship between Neural Language Model (NLM) perplexity and sentence readability. Starting from the evidence that NLMs implicitly acquire sophisticated linguistic knowledge from a huge amount of training data, our goal is to investigate whether perplexity is affected by linguistic features used to automatically assess sentence readability and if there is a correlation between the two metrics. Our findings suggest that this correlation is actually quite weak and the two metrics are affected by different linguistic phenomena.

---

##### Citation

```BibTeX
@inproceedings{miaschi2020neural,
  title={Is Neural Language Model Perplexity Related to Readability?},
  author={Miaschi, Alessio and Alzetta, Chiara and Brunato, Dominique and Dellâ€™Orletta, Felice and Venturi, Giulia},
  booktitle={Proceedings of the Seventh Italian Conference on Computational Linguistics (CLiC-it)},
  year={2020}
}



