<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Invited Talk at NLP4RE @ REFSQ 2025 (Barcelona, Spain) | Alessio Miaschi</title><meta name=keywords content><meta name=description content="On April 7 I will give an invated talk during the REFSQ 2025 Workshop NLP4RE.
Title: Evaluating Linguistic Abilities of Neural Language Models
Abstract: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to evaluating and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems. This talk explores recent studies that shed light on these abilities, highlighting how such insights enhance our understanding of model behaviour across various applications."><meta name=author content="Alessio Miaschi"><link rel=canonical href=https://alemiaschi.github.io/news/nlp4re_2025/><link crossorigin=anonymous href=/assets/css/stylesheet.ac30954b7ea20660ca1cb473400ecede9e601f17674446536180d3ca00f03328.css integrity="sha256-rDCVS36iBmDKHLRzQA7O3p5gHxdnREZTYYDTygDwMyg=" rel="preload stylesheet" as=style><link rel=icon href=https://alemiaschi.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://alemiaschi.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://alemiaschi.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://alemiaschi.github.io/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://alemiaschi.github.io/news/nlp4re_2025/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:url" content="https://alemiaschi.github.io/news/nlp4re_2025/"><meta property="og:site_name" content="Alessio Miaschi"><meta property="og:title" content="Invited Talk at NLP4RE @ REFSQ 2025 (Barcelona, Spain)"><meta property="og:description" content="On April 7 I will give an invated talk during the REFSQ 2025 Workshop NLP4RE.
Title: Evaluating Linguistic Abilities of Neural Language Models Abstract: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to evaluating and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems. This talk explores recent studies that shed light on these abilities, highlighting how such insights enhance our understanding of model behaviour across various applications."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="news"><meta property="article:published_time" content="2025-04-04T00:00:00+00:00"><meta property="article:modified_time" content="2025-04-04T00:00:00+00:00"><meta property="og:image" content="https://alemiaschi.github.io/featured.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://alemiaschi.github.io/featured.png"><meta name=twitter:title content="Invited Talk at NLP4RE @ REFSQ 2025 (Barcelona, Spain)"><meta name=twitter:description content="On April 7 I will give an invated talk during the REFSQ 2025 Workshop NLP4RE.
Title: Evaluating Linguistic Abilities of Neural Language Models
Abstract: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to evaluating and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems. This talk explores recent studies that shed light on these abilities, highlighting how such insights enhance our understanding of model behaviour across various applications."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"News","item":"https://alemiaschi.github.io/news/"},{"@type":"ListItem","position":2,"name":"Invited Talk at NLP4RE @ REFSQ 2025 (Barcelona, Spain)","item":"https://alemiaschi.github.io/news/nlp4re_2025/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Invited Talk at NLP4RE @ REFSQ 2025 (Barcelona, Spain)","name":"Invited Talk at NLP4RE @ REFSQ 2025 (Barcelona, Spain)","description":"On April 7 I will give an invated talk during the REFSQ 2025 Workshop NLP4RE.\nTitle: Evaluating Linguistic Abilities of Neural Language Models Abstract: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to evaluating and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems. This talk explores recent studies that shed light on these abilities, highlighting how such insights enhance our understanding of model behaviour across various applications.\n","keywords":[],"articleBody":"On April 7 I will give an invated talk during the REFSQ 2025 Workshop NLP4RE.\nTitle: Evaluating Linguistic Abilities of Neural Language Models Abstract: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to evaluating and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems. This talk explores recent studies that shed light on these abilities, highlighting how such insights enhance our understanding of model behaviour across various applications.\n","wordCount":"151","inLanguage":"en","image":"https://alemiaschi.github.io/featured.png","datePublished":"2025-04-04T00:00:00Z","dateModified":"2025-04-04T00:00:00Z","author":{"@type":"Person","name":"Alessio Miaschi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://alemiaschi.github.io/news/nlp4re_2025/"},"publisher":{"@type":"Organization","name":"Alessio Miaschi","logo":{"@type":"ImageObject","url":"https://alemiaschi.github.io/favicon.ico"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity=sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity=sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity=sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\begin{equation}",right:"\\end{equation}",display:!0},{left:"\\begin{equation*}",right:"\\end{equation*}",display:!0},{left:"\\begin{align}",right:"\\end{align}",display:!0},{left:"\\begin{align*}",right:"\\end{align*}",display:!0},{left:"\\begin{alignat}",right:"\\end{alignat}",display:!0},{left:"\\begin{gather}",right:"\\end{gather}",display:!0},{left:"\\begin{CD}",right:"\\end{CD}",display:!0}],throwOnError:!1})})</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://alemiaschi.github.io/ accesskey=h title="Alessio Miaschi"><img src=https://alemiaschi.github.io/logo.jpg alt aria-label=logo height=18 width=18>Alessio Miaschi</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://alemiaschi.github.io/news/ title=News><span>News</span></a></li><li><a href=https://alemiaschi.github.io/papers/ title=Papers><span>Papers</span></a></li><li><a href=https://alemiaschi.github.io/courses/ title="Courses & Theses"><span>Courses & Theses</span></a></li><li><a href=https://alemiaschi.github.io/talks/ title=Talks><span>Talks</span></a></li><li><a href=https://alemiaschi.github.io/projects/ title="Resources & Projects"><span>Resources & Projects</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Invited Talk at NLP4RE @ REFSQ 2025 (Barcelona, Spain)</h1><div class=post-meta><span title='2025-04-04 00:00:00 +0000 UTC'>April 2025</span>&nbsp;&#183;&nbsp;Alessio Miaschi</div></header><div class=post-content><p>On April 7 I will give an invated talk during the REFSQ 2025 Workshop NLP4RE.</p><h3><b>Title</b>: Evaluating Linguistic Abilities of Neural Language Models</h3><br><p><b>Abstract</b>: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to evaluating and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems. This talk explores recent studies that shed light on these abilities, highlighting how such insights enhance our understanding of model behaviour across various applications.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 Alessio Miaschi</span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>hugo</a>, <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>papermod</a>, &
<a href=https://github.com/pmichaillat/hugo-website/ rel=noopener target=_blank>hugo-website</a>.</span></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>