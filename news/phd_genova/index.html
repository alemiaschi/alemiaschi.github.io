<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Talk at AI Seminars 2024/25 | Alessio Miaschi</title>
<meta name="keywords" content="">
<meta name="description" content="On December 9 I gave a talk during the AI Seminars of the PhD program in Digital Humanities of the University of Genova. The aim of the seminars is to present experiences and practices of using AI in different fields, to increase knowledge and develop awareness about the opportunities and risks of using AI in our research fields.
Title: Evaluating Linguistic Abilities of Neural Language Models
Abstract: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to analyzing and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems.
This talk will be divided into two parts. The first part offers an overview of Language Models (LMs) and the recent advancements achieved by these models in the past few years. In the second part, we will focus on recent studies that examine these models’ implicit linguistic abilities, exploring how these insights can enhance our understanding of model behaviour across various tasks and applications.">
<meta name="author" content="Alessio Miaschi">
<link rel="canonical" href="http://localhost:1313/news/phd_genova/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.ac30954b7ea20660ca1cb473400ecede9e601f17674446536180d3ca00f03328.css" integrity="sha256-rDCVS36iBmDKHLRzQA7O3p5gHxdnREZTYYDTygDwMyg=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/news/phd_genova/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:url" content="http://localhost:1313/news/phd_genova/">
  <meta property="og:site_name" content="Alessio Miaschi">
  <meta property="og:title" content="Talk at AI Seminars 2024/25">
  <meta property="og:description" content="On December 9 I gave a talk during the AI Seminars of the PhD program in Digital Humanities of the University of Genova. The aim of the seminars is to present experiences and practices of using AI in different fields, to increase knowledge and develop awareness about the opportunities and risks of using AI in our research fields.
Title: Evaluating Linguistic Abilities of Neural Language Models Abstract: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to analyzing and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems. This talk will be divided into two parts. The first part offers an overview of Language Models (LMs) and the recent advancements achieved by these models in the past few years. In the second part, we will focus on recent studies that examine these models’ implicit linguistic abilities, exploring how these insights can enhance our understanding of model behaviour across various tasks and applications.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="news">
    <meta property="article:published_time" content="2024-12-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-12-09T00:00:00+00:00">
    <meta property="og:image" content="http://localhost:1313/featured.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:1313/featured.png">
<meta name="twitter:title" content="Talk at AI Seminars 2024/25">
<meta name="twitter:description" content="On December 9 I gave a talk during the AI Seminars of the PhD program in Digital Humanities of the University of Genova. The aim of the seminars is to present experiences and practices of using AI in different fields, to increase knowledge and develop awareness about the opportunities and risks of using AI in our research fields.
Title: Evaluating Linguistic Abilities of Neural Language Models
Abstract: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to analyzing and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems.
This talk will be divided into two parts. The first part offers an overview of Language Models (LMs) and the recent advancements achieved by these models in the past few years. In the second part, we will focus on recent studies that examine these models’ implicit linguistic abilities, exploring how these insights can enhance our understanding of model behaviour across various tasks and applications.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "News",
      "item": "http://localhost:1313/news/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Talk at AI Seminars 2024/25",
      "item": "http://localhost:1313/news/phd_genova/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Talk at AI Seminars 2024/25",
  "name": "Talk at AI Seminars 2024\/25",
  "description": "On December 9 I gave a talk during the AI Seminars of the PhD program in Digital Humanities of the University of Genova. The aim of the seminars is to present experiences and practices of using AI in different fields, to increase knowledge and develop awareness about the opportunities and risks of using AI in our research fields.\nTitle: Evaluating Linguistic Abilities of Neural Language Models Abstract: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to analyzing and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems. This talk will be divided into two parts. The first part offers an overview of Language Models (LMs) and the recent advancements achieved by these models in the past few years. In the second part, we will focus on recent studies that examine these models’ implicit linguistic abilities, exploring how these insights can enhance our understanding of model behaviour across various tasks and applications.\n",
  "keywords": [
    
  ],
  "articleBody": "On December 9 I gave a talk during the AI Seminars of the PhD program in Digital Humanities of the University of Genova. The aim of the seminars is to present experiences and practices of using AI in different fields, to increase knowledge and develop awareness about the opportunities and risks of using AI in our research fields.\nTitle: Evaluating Linguistic Abilities of Neural Language Models Abstract: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to analyzing and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems. This talk will be divided into two parts. The first part offers an overview of Language Models (LMs) and the recent advancements achieved by these models in the past few years. In the second part, we will focus on recent studies that examine these models’ implicit linguistic abilities, exploring how these insights can enhance our understanding of model behaviour across various tasks and applications.\n",
  "wordCount" : "234",
  "inLanguage": "en",
  "image":"http://localhost:1313/featured.png","datePublished": "2024-12-10T00:00:00Z",
  "dateModified": "2024-12-09T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Alessio Miaschi"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/news/phd_genova/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Alessio Miaschi",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Alessio Miaschi">
                <img src="http://localhost:1313/logo.jpg" alt="" aria-label="logo"
                    height="18"
                    width="18">Alessio Miaschi</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/news/" title="News">
                    <span>News</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/papers/" title="Papers">
                    <span>Papers</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/courses/" title="Courses &amp; Theses">
                    <span>Courses &amp; Theses</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/talks/" title="Talks">
                    <span>Talks</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/projects/" title="Resources &amp; Projects">
                    <span>Resources &amp; Projects</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Talk at AI Seminars 2024/25
    </h1>
    <div class="post-meta"><span title='2024-12-09 00:00:00 +0000 UTC'>December 2024</span>&nbsp;&middot;&nbsp;Alessio Miaschi

</div>
  </header> 
  <div class="post-content"><p>On December 9 I gave a talk during the AI Seminars of the PhD program in Digital Humanities of the University of Genova. The aim of the seminars is to present experiences and practices of using AI in different fields, to increase knowledge and develop awareness about the opportunities and risks of using AI in our research fields.</p>
<h3><b>Title</b>: Evaluating Linguistic Abilities of Neural Language Models</h3><br/>
<p><b>Abstract</b>: The field of Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, driven largely by the shift from traditional approaches to state-of-the-art neural network-based algorithms. Among these, Large-scale Language Models (LLMs) have shown remarkable performance across a wide range of tasks and in generating coherent and contextually relevant texts. This improvement, however, comes at the cost of interpretability, since deep neural models offer little transparency about their inner workings and their abilities. In response, a growing body of research is dedicated to analyzing and interpreting LLMs, aiming to shed light on the inner workings and linguistic abilities encoded by these systems.
This talk will be divided into two parts. The first part offers an overview of Language Models (LMs) and the recent advancements achieved by these models in the past few years. In the second part, we will focus on recent studies that examine these models’ implicit linguistic abilities, exploring how these insights can enhance our understanding of model behaviour across various tasks and applications.</p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 Alessio Miaschi</span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">hugo</a>, <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">papermod</a>, &amp;
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">hugo-website</a>.
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
