---
title: Lab @ Lectures on Computational Linguistics 2023
event: Lectures on Computational Linguistics 2023
event_url: https://www.ai-lc.it/lectures/lectures-2023-it/

location: Polo Piagge, University of Pisa, Pisa

cover:
    image: "featured.png"
    
# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date_event: "2023-05-31T13:00:00Z"
date: "2023-05-23"
all_day: true

# Schedule page publish date (NOT talk date).
publishDate: "2023-05-23T00:00:00Z"

---

I am glad to announce that on May 31 I will be hosting with <a href="https://gsarti.com/">Gabriele Sarti</a> a laboratory focused on the interpretability of Neural Language Models (NLMs) at the 2023 edition of the Lectures on Computational Linguistics. <br/>Below you can find title and abstract of the lab:
<br/>
<h3><b>Title</b>: Explaining Neural Language Models from Internal Representations to Model Predictions</h3><br/>

<b>Abstract</b>: As language models become increasingly complex and sophisticated, the processes leading to their predictions are growing increasingly difficult to understand. Research in NLP interpretability focuses on explaining the rationales driving model predictions and is crucial for building trust and transparency in the usage of these systems in real-world scenarios.

In this laboratory, we will explore various techniques for analyzing Neural Language Models, such as feature attribution methods and diagnostic classifiers. Besides common approaches to inspect modelsâ€™ internal representations, we will also introduce prompting techniques to elicit model responses and motivate their usage as alternative methods for the behavioral study of model generations.
