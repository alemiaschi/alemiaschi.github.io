@Article{info14030144,
	AUTHOR = {Miaschi, Alessio and Alzetta, Chiara and Brunato, Dominique and Dellâ€™Orletta, Felice and Venturi, Giulia},
	TITLE = {Testing the Effectiveness of the Diagnostic Probing Paradigm on Italian Treebanks},
	JOURNAL = {Information},
	VOLUME = {14},
	YEAR = {2023},
	NUMBER = {3},
	ARTICLE-NUMBER = {144},
	URL = {https://www.mdpi.com/2078-2489/14/3/144},
	ISSN = {2078-2489},
	ABSTRACT = {The outstanding performance recently reached by neural language models (NLMs) across many natural language processing (NLP) tasks has steered the debate towards understanding whether NLMs implicitly learn linguistic competence. Probes, i.e., supervised models trained using NLM representations to predict linguistic properties, are frequently adopted to investigate this issue. However, it is still questioned if probing classification tasks really enable such investigation or if they simply hint at surface patterns in the data. This work contributes to this debate by presenting an approach to assessing the effectiveness of a suite of probing tasks aimed at testing the linguistic knowledge implicitly encoded by one of the most prominent NLMs, BERT. To this aim, we compared the performance of probes when predicting gold and automatically altered values of a set of linguistic features. Our experiments were performed on Italian and were evaluated across BERT&rsquo;s layers and for sentences with different lengths. As a general result, we observed higher performance in the prediction of gold values, thus suggesting that the probing model is sensitive to the distortion of feature values. However, our experiments also showed that the length of a sentence is a highly influential factor that is able to confound the probing model&rsquo;s predictions.},
	DOI = {10.3390/info14030144}
}



